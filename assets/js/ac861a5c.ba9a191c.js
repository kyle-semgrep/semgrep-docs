"use strict";(self.webpackChunkmegadocs=self.webpackChunkmegadocs||[]).push([[37219],{28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>t});var o=s(96540);const i={},r=o.createContext(i);function a(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),o.createElement(r.Provider,{value:n},e.children)}},59487:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"kb/semgrep-code/scan-engine-kill","title":"Troubleshoot monorepo scan failures","description":"Troubleshoot scan failures on monorepos by studying logs, compartmentalizing scans, increasing RAM, and running jobs in parallel.","source":"@site/docs/kb/semgrep-code/scan-engine-kill.md","sourceDirName":"kb/semgrep-code","slug":"/kb/semgrep-code/scan-engine-kill","permalink":"/semgrep-docs/kb/semgrep-code/scan-engine-kill","draft":false,"unlisted":false,"editUrl":"https://github.com/kyle-semgrep/semgrep-docs/edit/main?base=kyle-semgrep:main/docs/kb/semgrep-code/scan-engine-kill.md","tags":[{"inline":true,"label":"Semgrep Code","permalink":"/semgrep-docs/tags/semgrep-code"}],"version":"current","lastUpdatedAt":1752254305000,"frontMatter":{"title":"Troubleshoot monorepo scan failures","description":"Troubleshoot scan failures on monorepos by studying logs, compartmentalizing scans, increasing RAM, and running jobs in parallel.","tags":["Semgrep Code"]},"sidebar":"kbSidebar","previous":{"title":"How to run different versions of Semgrep","permalink":"/semgrep-docs/kb/semgrep-code/run-specific-version"},"next":{"title":"A Semgrep scan is having a problem - what next?","permalink":"/semgrep-docs/kb/semgrep-code/semgrep-scan-troubleshooting"}}');var i=s(74848),r=s(28453);const a={title:"Troubleshoot monorepo scan failures",description:"Troubleshoot scan failures on monorepos by studying logs, compartmentalizing scans, increasing RAM, and running jobs in parallel.",tags:["Semgrep Code"]},t='Troubleshooting "You are seeing this because the engine was killed" on monorepos',l={},c=[{value:"Determining the size of your monorepo",id:"determining-the-size-of-your-monorepo",level:2},{value:"Scanning components separately",id:"scanning-components-separately",level:2},{value:"Serializing types of scans",id:"serializing-types-of-scans",level:2},{value:"Increasing RAM",id:"increasing-ram",level:2},{value:"Establish RAM baseline and avoid swap memory",id:"establish-ram-baseline-and-avoid-swap-memory",level:3},{value:"Parallelization",id:"parallelization",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"troubleshooting-you-are-seeing-this-because-the-engine-was-killed-on-monorepos",children:'Troubleshooting "You are seeing this because the engine was killed" on monorepos'})}),"\n",(0,i.jsx)(n.p,{children:"Scans can fail to complete on large monorepos. This article describes possible solutions, such as:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/kb/semgrep-ci/scan-monorepo-in-parts",children:"Scanning the components of a monorepo separately"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Serializing the type of scan performed."}),"\n",(0,i.jsx)(n.li,{children:"Increasing the RAM of the job runner for CI jobs."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Given the following log or similar:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"[ERROR] Error while running rules:\n          You are seeing this because the engine was killed.\n\n          The most common reason this happens is because it used too much memory.\n          If your repo is large (~10k files or more), you have three options:\n          1. Increase the amount of memory available to semgrep\n          2. Reduce the number of jobs semgrep runs with via `-j <jobs>`.  We\n            recommend using 1 job if you are running out of memory.\n          3. Scan the repo in parts (contact us for help)\n\n          Otherwise, it is likely that semgrep is hitting the limit on only some\n          files. In this case, you can try to set the limit on the amount of memory\n          semgrep can use on each file with `--max-memory <memory>`. We recommend\n          lowering this to a limit 70% of the available memory. For CI runs with\n          interfile analysis, the default max-memory is 5000MB. Without, the default\n          is unlimited.\n\n          The last thing you can try if none of these work is to raise the stack\n          limit with `ulimit -s <limit>`.\n\n          If you have tried all these steps and still are seeing this error, please\n          contact us.\n\n           Error: semgrep-core exited with unexpected output\n"})}),"\n",(0,i.jsx)(n.h2,{id:"determining-the-size-of-your-monorepo",children:"Determining the size of your monorepo"}),"\n",(0,i.jsx)(n.p,{children:"By default, Semgrep places resource limitations on the size of file scanned and memory allocated."}),"\n",(0,i.jsx)(n.p,{children:"However, Semgrep does not place limitations on the number of files scanned and scanning a large monorepo can involve thousands of files."}),"\n",(0,i.jsx)(n.p,{children:"To determine how many files are getting scanned:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"View the Semgrep scan output in your CI logs. This step depends on your CI provider."}),"\n",(0,i.jsxs)(n.li,{children:["In the CI logs, search for the section ",(0,i.jsx)(n.strong,{children:"Scan Status"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"A sample Semgrep scan output can look like this:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-console",children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Scan Status \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  Scanning 91749 files tracked by git with 1068 Code rules, 498 Pro rules:\n\n  Language      Rules    Files          Origin      Rules\n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  <multilang>      60   199251          Community     551\n  ts              166    26672          Pro rules     498\n  python          314     8089          Custom         19\n  scala            13     5415\n  json              1     4149\n  yaml              7     1952\n  js              160     1084\n  terraform        13      470\n  bash              4      408\n  go               95      228\n  ruby             22      228\n  php              25       99\n  swift            41       89\n  html              1       72\n  dockerfile        2       31\n  c                 9       16\n  rust             49        8\n  java            156        2\n  kotlin           47        1\n"})}),"\n",(0,i.jsx)(n.p,{children:"Now you have a good idea of the size of your monorepo. After establishing the size and breakdown of your files by programming language, you can decide what adjustments to make for a scan to succeed."}),"\n",(0,i.jsx)(n.h2,{id:"scanning-components-separately",children:"Scanning components separately"}),"\n",(0,i.jsxs)(n.p,{children:["Based on the composition provided by the logs, you may be able to determine if your repository is modular. If so, you can try ",(0,i.jsx)(n.a,{href:"/docs/kb/semgrep-ci/scan-monorepo-in-parts/",children:"scanning the components separately"}),"."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Semgrep Code still performs ",(0,i.jsxs)(n.a,{href:"/semgrep-code/semgrep-pro-engine-intro#types-of-semgrep-code-analysis",children:[(0,i.jsx)("i",{class:"fa-regular fa-file-lines"})," interfile analysis"]})," on each module. If the modules are functionally separate, running separate scans shouldn't result in a reduction in findings."]})}),"\n",(0,i.jsx)(n.h2,{id:"serializing-types-of-scans",children:"Serializing types of scans"}),"\n",(0,i.jsx)(n.p,{children:"Avoid exhausting resource limits by running Semgrep Code, Supply Chain, and Secrets serially instead of simultaneously. That is, instead of:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-console",children:" semgrep ci\n"})}),"\n",(0,i.jsx)(n.p,{children:"You can run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"semgrep ci --code\nsemgrep ci --supply-chain\nsemgrep ci --secrets\n"})}),"\n",(0,i.jsx)(n.p,{children:"As a result, less memory is used in total at any point in time."}),"\n",(0,i.jsx)(n.h2,{id:"increasing-ram",children:"Increasing RAM"}),"\n",(0,i.jsx)(n.p,{children:"Lastly, you can also tackle a large scan by increasing the RAM."}),"\n",(0,i.jsx)(n.h3,{id:"establish-ram-baseline-and-avoid-swap-memory",children:"Establish RAM baseline and avoid swap memory"}),"\n",(0,i.jsx)(n.p,{children:"First, establish how much memory is required to scan. Determining the total amount of memory required not only helps avoid killed scans but also helps prevent use of swap memory. Semgrep and other SAST tools make heavy use of disk I/O, and swapping in and out with a swap file significantly reduces performance."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"In the early phases of your scan deployment, start with a relatively larger runner or Kubernetes pod that has lots of memory."}),"\n",(0,i.jsxs)(n.li,{children:["Perform the scan with the ",(0,i.jsx)(n.code,{children:"-j 1"})," option (",(0,i.jsx)(n.a,{href:"/docs/cli-reference",children:"see CLI reference"}),"). This sets the number of jobs to 1 (no parallelization of subprocesses)."]}),"\n",(0,i.jsx)(n.li,{children:"Enable a swap monitor for the entire duration of the scan to ensure an accurate assessment of RAM used, for example, running a script that samples the memory frequently:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"$ free -m\n"})}),"\n",(0,i.jsx)(n.p,{children:"to see both your RAM and your swap space usage in Linux."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Then perhaps add 10% more RAM to your final memory tally to account for churn, increase in code, and so on. This is something you must gauge."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"parallelization",children:"Parallelization"}),"\n",(0,i.jsx)(n.p,{children:"Once you have determined the RAM required to scan your large codebase, you can introduce parallelization to speed up the scan."}),"\n",(0,i.jsx)(n.p,{children:"In the previous section, you determined the total memory required for a configuration with no parallelization. Now, you can begin testing different parallelization configurations to improve scan speed, while still monitoring for any swap usage."}),"\n",(0,i.jsxs)(n.p,{children:["To increase parallelization, first try the scan with ",(0,i.jsx)(n.code,{children:"-j 2"})," for two jobs. For two jobs, memory usage will typically be just less than twice the amount required for one job, and that trend continues as the number of jobs increases."]}),"\n",(0,i.jsxs)(n.p,{children:["Furthermore, there is overhead in parallelization: the total RAM required for a ",(0,i.jsx)(n.code,{children:"-j 2"})," scan is greater than a ",(0,i.jsx)(n.code,{children:"-j 1"})," scan for the same codebase, but you should see a decrease in total scan time."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);